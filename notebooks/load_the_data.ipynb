{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d7b5580",
   "metadata": {},
   "source": [
    "# Loading the HST data, normalising and shifting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccd9ffa",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3649c48a",
   "metadata": {},
   "source": [
    "This workbook takes the HST fits files and creates numpy arrays of shifted and normalised data. It then looks at how accurately the alignment was done. The bottom part of this notebook is specific to the SiIV lines and will need changing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95058fa4",
   "metadata": {},
   "source": [
    "## The code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d99955",
   "metadata": {},
   "source": [
    "The code written below uses functions in ```src/calculations.py```. It is capable of looking for variations in the entire dataset (e.g. it is capable of running over each HST visit)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8049c3d0",
   "metadata": {},
   "source": [
    "### Import the standard routines and load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9992dea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository home directory: /Users/bdrdavies/Desktop/exocomets\n",
      "The following tasks in the costools package can be run with TEAL:\n",
      "         splittag                 timefilter                 x1dcorr\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json, sys, os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc, cm\n",
    "\n",
    "# get the path of the current directory\n",
    "path = os.getcwd()\n",
    "home = os.path.dirname(path)\n",
    "\n",
    "# Print the repository home directory\n",
    "print(\"Repository home directory:\",home)\n",
    "\n",
    "# Add the src folder to the system path\n",
    "sys.path.append(home+'/src')\n",
    "\n",
    "# Import the python functions from src\n",
    "from calculations import Calc, Model, Stats\n",
    "\n",
    "# We shorten the functions name to make it easier to call the required a functions\n",
    "c   = Calc()\n",
    "m   = Model()\n",
    "s   = Stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514c62f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing parameters from a json file.\n",
    "with open(home+'/params.json') as param_file:    \n",
    "   param = json.load(param_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dcde6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read in the data directories we are using. To see what directories this is open params.json.\n",
    "datadirs = param[\"datadirs\"]\n",
    "\n",
    "# We select part A which is the red end of the spectrum (the other part being B, which is the blue end)\n",
    "part     = param[\"BetaPictoris\"][\"part\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784b303a",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167bdb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = []\n",
    "\n",
    "print(\"Data used for this analysis:\")\n",
    "\n",
    "for i in sorted(datadirs):\n",
    "    if param[\"filenames\"][\"split_files\"] == 'yes':\n",
    "        if datadirs[i][5:-1] in [\"2017-04-23\",\"2017-06-10\",\"2017-08-04\",\"2017-10-21\",\"2017-11-26\",\"2018-03-17\",\"2018-05-09\"]:\n",
    "            print(\"\\n\",datadirs[i])\n",
    "            D.append(c.GetData(param, home+'/'+datadirs[i]))\n",
    "    else:\n",
    "        print(\"\\n\",datadirs[i][5:-1])\n",
    "        D.append(c.GetData(param, home+'/'+datadirs[i]))\n",
    "    \n",
    "# We save the data\n",
    "if param[\"filenames\"][\"split_files\"] == \"yes\":\n",
    "    np.savez(home+'/data/D_'+part+'_split.npz', D, dtype=object)\n",
    "else:\n",
    "    np.savez(home+'/data/D_'+part+'.npz', D, dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca09f99",
   "metadata": {},
   "source": [
    "### We now normalise, shift and re-normalise the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b720675e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the data into the multidimentional array D\n",
    "if param[\"filenames\"][\"split_files\"] == \"yes\":\n",
    "    D = c.LoadData(home+'/data/D_'+part+'_split.npz')\n",
    "else:\n",
    "    D = c.LoadData(home+'/data/D_'+part+'.npz')\n",
    "    \n",
    "# Normalise the data\n",
    "Dn = c.NormSpec(param, D)\n",
    "\n",
    "# Shift the data relative to the first spectrum of each visit\n",
    "Dns = c.ShiftSpec(param, Dn)\n",
    "\n",
    "# Re normalise the data\n",
    "Dnsn = c.NormSpec(param, Dns)\n",
    "\n",
    "# We save the normalised and shifted data\n",
    "if param[\"filenames\"][\"split_files\"] == \"yes\":\n",
    "    np.savez(home+'/data/Dnsn_'+part+'_split.npz', Dnsn, dtype=object)\n",
    "else:\n",
    "    np.savez(home+'/data/Dnsn_'+part+'.npz', Dnsn, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf93772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the parameters for the plots\n",
    "plotting_params = {'backend': 'wxAgg',\n",
    "                   'font.family': 'serif',\n",
    "                   'font.size': 22,\n",
    "                   'lines.markersize' : 2,\n",
    "                   'axes.labelsize': 22,\n",
    "                   'legend.fontsize': 22,\n",
    "                   'xtick.labelsize': 22,\n",
    "                   'ytick.labelsize': 22,\n",
    "                   'text.usetex': True}\n",
    "\n",
    "plt.rcParams.update(plotting_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbc09de",
   "metadata": {},
   "source": [
    "### Let us have a quick look at how well the alignment worked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446e95ac",
   "metadata": {},
   "source": [
    "We do this by fitting a Gaussian to the non-variable CO line and measure the lateral movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79e4ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def gauss(x,a,x0,sigma,bl):\n",
    "    return -a*np.exp(-(x-x0)**2/(2*(sigma)**2))+bl\n",
    "\n",
    "w = Dnsn[0][0][0]\n",
    "spec        = []\n",
    "minimums = []\n",
    "\n",
    "s1, s2 = c.RegionSelect(w, 1391.9, 1393.3)\n",
    "w_c = w[s1:s2]\n",
    "\n",
    "for i in range(len(Dnsn)):          # Cycle over number of visits\n",
    "    for j in range(len(Dnsn[i])):   # Cycle over number of fits files each visit\n",
    "        spec.append(Dnsn[i][j][1])\n",
    "        minimums.append((w[s1:s2][np.argmin(Dnsn[i][j][1][s1:s2])]))\n",
    "\n",
    "spec = np.array(spec)\n",
    "\n",
    "lateral = []\n",
    "\n",
    "fig = plt.figure(figsize=(10.0,6.0))\n",
    "for i in range(len(spec)):\n",
    "    popt,pcov = curve_fit(gauss,w_c,spec[i][s1:s2],p0=[3.5e-13,1392.6,0.1,3.3e-13], bounds=([-np.inf, -np.inf, -np.inf], [np.inf, np.inf, np.inf]), maxfev = 2800)\n",
    "    #print(popt)                    \n",
    "    lateral.append(popt[1])\n",
    "    plt.step(w,spec[i],color='k',alpha=0.05)\n",
    "    plt.plot(w_c,gauss(w_c,*popt),color=\"red\")\n",
    "\n",
    "plt.xlim(1391,1394)\n",
    "plt.ylim(0,0.5e-12)\n",
    "plt.xlabel(r'Wavelength [\\AA]')\n",
    "plt.ylabel(r'Flux [erg/s/cm$^2$/\\AA]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a814f666",
   "metadata": {},
   "outputs": [],
   "source": [
    "lateral = np.array(lateral)\n",
    "lateral = lateral - np.median(lateral)\n",
    "\n",
    "print(\"The standard deviation of the lateral shifts (in Ångstrøm):\",np.std(lateral))\n",
    "\n",
    "fig = plt.figure(figsize=(10.0,6.0))\n",
    "plt.scatter(np.arange(len(lateral)),lateral)\n",
    "plt.xlabel(r'Number of spectra')\n",
    "plt.ylabel(r'Wavelength shift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab51b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def gauss(x,a,x0,sigma,bl):\n",
    "    return -a*np.exp(-(x-x0)**2/(2*(sigma)**2))+bl\n",
    "\n",
    "w = Dnsn[0][0][0]\n",
    "s1, s2 = c.RegionSelect(w, 1320, 1479)\n",
    "w_c = w[s1:s2]\n",
    "\n",
    "spec_c = []\n",
    "for i in range(len(spec)):\n",
    "    spec_c.append(spec[i][s1:s2])\n",
    "\n",
    "spec_c = np.array(spec_c)\n",
    "\n",
    "spec_range   = len(w_c)\n",
    "rows         = len(spec_c)\n",
    "\n",
    "S            = spec_c.reshape(rows,spec_range)\n",
    "cmap = plt.get_cmap('inferno')\n",
    "\n",
    "fig = plt.figure(figsize=(16.0,10.0))\n",
    "plt.imshow(S,cmap=cmap,extent=[w_c[0],w_c[-1],0,len(spec_c)],interpolation='none',aspect='auto')\n",
    "plt.xlabel(r'Wavelength [\\AA]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
